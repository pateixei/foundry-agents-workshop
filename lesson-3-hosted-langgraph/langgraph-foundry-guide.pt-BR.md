## Como Hospedar um Agente LangGraph no Azure AI Foundry

> üá∫üá∏ **[Read in English](langgraph-foundry-guide.md)**

### Pr√©-requisitos de Infraestrutura Azure

1. **Azure AI Foundry (account + projeto)** ‚Äî O Foundry fornece o API gateway (Responses API), o Capability Host que gerencia o cont√™iner e acesso ao modelo.

2. **Azure Container Registry (ACR)** ‚Äî para armazenar a imagem Docker do seu agente.

3. **Modelo implantado** ‚Äî uma implanta√ß√£o de modelo (ex., `gpt-4.1`) no Foundry, acess√≠vel via Azure OpenAI.

4. **Managed Identity com RBAC** ‚Äî a identidade do projeto precisa de:
   - **AcrPull** no Container Registry (para puxar a imagem)
   - **Cognitive Services OpenAI User** na conta Foundry (para o cont√™iner chamar o modelo)

5. **Capability Host** ‚Äî recurso Foundry que gerencia o ciclo de vida do cont√™iner (start/stop/roteamento). Criado automaticamente ao registrar o agente.

### O Que Muda no C√≥digo LangGraph

Seu c√≥digo LangGraph em si (grafo, ferramentas, n√≥s) **n√£o muda**. As adapta√ß√µes s√£o apenas na camada de integra√ß√£o:

#### 1. Depend√™ncia √∫nica: `azure-ai-agentserver-langgraph`

```
azure-ai-agentserver-langgraph==1.0.0b10
```

Este pacote traz tudo: o adaptador que exp√µe o grafo como Responses API, mais depend√™ncias LangGraph/LangChain.

#### 2. Adaptador `from_langgraph` no ponto de entrada

Em vez de executar o grafo manualmente, voc√™ o exp√µe via adaptador:

```python
from azure.ai.agentserver.langgraph import from_langgraph

agent = build_agent()       # seu StateGraph compilado
adapter = from_langgraph(agent)
adapter.run()                # abre servidor HTTP na porta 8088
```

Isso transforma o grafo LangGraph em um servidor Responses API que o Foundry sabe chamar.

#### 3. LLM via `AzureChatOpenAI` com credencial Azure

O cont√™iner usa `DefaultAzureCredential` (managed identity) para autenticar no Azure OpenAI:

```python
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from langchain_openai import AzureChatOpenAI

credential = DefaultAzureCredential()
token_provider = get_bearer_token_provider(credential, "https://cognitiveservices.azure.com/.default")

llm = AzureChatOpenAI(
    azure_deployment=os.getenv("AZURE_AI_MODEL_DEPLOYMENT_NAME", "gpt-4o-mini"),
    azure_ad_token_provider=token_provider,
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_version="2025-01-01-preview",
)
```

#### 4. Vari√°veis de ambiente consumidas pelo cont√™iner

O Foundry injeta essas vari√°veis de ambiente ao iniciar o cont√™iner:

| Vari√°vel | Descri√ß√£o |
|---|---|
| `AZURE_AI_PROJECT_ENDPOINT` | Endpoint do projeto Foundry |
| `AZURE_AI_MODEL_DEPLOYMENT_NAME` | Nome da implanta√ß√£o do modelo |
| `AZURE_OPENAI_ENDPOINT` | Endpoint OpenAI do Foundry (`https://<account>.openai.azure.com/`) |
| `AZURE_CLIENT_ID` | Client ID da managed identity |

#### 5. Monkey-patch necess√°rio (bug conhecido)

O pacote `azure-ai-agentserver-core` v1.0.0b10 n√£o aceita o campo `id` que o Foundry envia em `AgentReference`. Voc√™ precisa fazer patch em `_deserialize_agent_reference` para ignorar campos extras ‚Äî como implementado em [main.py](labs/solution/main.py#L211-L245).

#### 6. Dockerfile

```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . ./user_agent/
EXPOSE 8088
CMD ["python", "user_agent/main.py"]
```

A porta **8088** √© esperada pelo Foundry para agentes LangGraph.

### Fluxo de Implanta√ß√£o

1. **Construir a imagem** no ACR: `az acr build --registry <acr> --image lg-market-agent:v1 .`
2. **Registrar o agente** via SDK (`create_hosted_agent.py`) ou CLI (`az cognitiveservices agent create`), passando a imagem ACR e vari√°veis de ambiente.
3. **Iniciar o agente**: `az cognitiveservices agent start --name <name> --agent-version 1`
4. **Testar** via portal Foundry (playground) ou cliente program√°tico usando a Responses API.

### Resumo das Diferen√ßas vs. LangGraph Standalone

| Aspecto | LangGraph Standalone | LangGraph no Foundry |
|---|---|---|
| Execu√ß√£o | Voc√™ executa `graph.invoke()` | Adaptador `from_langgraph(graph).run()` exp√µe HTTP |
| Autentica√ß√£o LLM | Chave API ou qualquer m√©todo | Managed Identity via `DefaultAzureCredential` |
| System prompt | Passado no c√≥digo | Passado no c√≥digo (portal n√£o permite edi√ß√£o) |
| Porta | Qualquer | **8088** (conven√ß√£o Foundry) |
| Depend√™ncia extra | Nenhuma | `azure-ai-agentserver-langgraph` |
| Deploy | Onde voc√™ quiser | Imagem Docker no ACR ‚Üí Foundry hosted agent |
