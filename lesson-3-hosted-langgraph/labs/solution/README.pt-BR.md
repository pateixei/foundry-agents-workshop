# Li√ß√£o 2 - Agente Hospedado com LangGraph no Azure AI Foundry

> üá∫üá∏ **[Read in English](README.md)**

Nesta li√ß√£o, criamos um **agente hospedado** no Azure AI Foundry
usando o framework **LangGraph** do LangChain.

## Arquitetura

O agente segue o padr√£o **ReAct** (Reason + Act):

1. O LLM recebe a mensagem do usu√°rio
2. Decide se precisa chamar uma ferramenta ou responder diretamente
3. Se chamou uma ferramenta, executa e retorna o resultado ao LLM
4. O ciclo se repete at√© o LLM produzir uma resposta final

```
START -> llm_call -> [tool_calls?] -> environment -> llm_call -> ... -> END
```

## Ferramentas Dispon√≠veis

| Ferramenta | Descri√ß√£o |
|---|---|
| `get_stock_price` | Consulta pre√ßos de a√ß√µes (PETR4, VALE3, AAPL, etc.) |
| `get_market_summary` | Resumo dos principais √≠ndices (Ibovespa, S&P 500, etc.) |
| `get_exchange_rate` | Taxa de c√¢mbio (USD/BRL, EUR/BRL, BTC/USD, etc.) |

> **Nota:** As ferramentas usam dados simulados para fins educacionais.

## Estrutura de Arquivos

```
lesson-3-hosted-langgraph/labs/solution/
  main.py                  # Agente LangGraph + servidor do agente hospedado
  # create_hosted_agent.py movido para prereq/
  test_agent.py            # Script de teste para executar o agente
  deploy.ps1               # Script completo de implanta√ß√£o (CLI)
  requirements.txt         # Depend√™ncias Python
  Dockerfile               # Cont√™iner para agente hospedado
  README.md                # Este arquivo
```

## Como o Agente Hospedado Funciona

O pacote `azure-ai-agentserver-langgraph` fornece o adaptador que:

1. Recebe um grafo LangGraph compilado
2. Exp√µe a **Responses API** na porta 8088
3. O Foundry roteia chamadas do cliente para o cont√™iner

```python
from azure.ai.agentserver.langgraph import from_langgraph
agent = build_agent()          # StateGraph compilado
adapter = from_langgraph(agent)
adapter.run()                  # Inicia servidor na porta 8088
```

## Pr√©-requisitos

- Infraestrutura da pasta `prereq/` j√° implantada (inclui **Capability Host** e Storage Account)
- Azure CLI instalado e autenticado (`az login`)
- Python 3.12+

> **Nota**: O Capability Host √© um componente de infraestrutura cr√≠tico que habilita hosted agents.
> Ele √© provisionado automaticamente pelo `prereq/main.bicep`. Veja [capability-host.pt-BR.md](../../../capability-host.pt-BR.md) para detalhes.

## Implanta√ß√£o Passo a Passo

O script `deploy.ps1` automatiza os passos abaixo, mas se voc√™ precisar fazer
manualmente ou entender o que acontece, siga a sequ√™ncia:

### 1. Verificar Capability Host

Agentes hospedados requerem um **Capability Host** no n√≠vel da conta.
Ele √© provisionado automaticamente pelo `prereq/main.bicep`. Verifique com:

```powershell
az rest --method GET `
    --uri "https://management.azure.com/subscriptions/<SUB_ID>/resourceGroups/<RG>/providers/Microsoft.CognitiveServices/accounts/<FOUNDRY_NAME>/capabilityHosts/default?api-version=2025-04-01-preview" `
    --query "properties.provisioningState" -o tsv
# Output esperado: Succeeded
```

### 2. Construir Imagem no ACR

```powershell
cd lesson-2/langgraph-agent
az acr build --registry <ACR_NAME> --image lg-market-agent:v1 --file Dockerfile . --no-logs
```

> **Nota Windows:** Use `--no-logs` para evitar `UnicodeEncodeError` causado por
> colorama/cp1252 ao exibir logs de build do ACR no PowerShell 5.1.

### 3. Permiss√µes RBAC (managed identity do projeto)

O projeto Foundry tem uma managed identity que precisa de duas roles:

| Role | Escopo | Motivo |
|---|---|---|
| **AcrPull** | Container Registry | Para puxar a imagem do cont√™iner |
| **Cognitive Services OpenAI User** | AI Foundry Account | Para o cont√™iner chamar o modelo GPT |

```powershell
# Obter o principal ID do projeto
$PRINCIPAL = az resource show `
    --ids "/subscriptions/<SUB>/resourceGroups/<RG>/providers/Microsoft.CognitiveServices/accounts/<FOUNDRY>/projects/<PROJECT>" `
    --query "identity.principalId" -o tsv

# AcrPull no ACR
az role assignment create --assignee $PRINCIPAL --role "AcrPull" `
    --scope $(az acr show --name <ACR> --query id -o tsv)

# OpenAI User na conta Foundry
az role assignment create --assignee $PRINCIPAL --role "Cognitive Services OpenAI User" `
    --scope "/subscriptions/<SUB>/resourceGroups/<RG>/providers/Microsoft.CognitiveServices/accounts/<FOUNDRY>"
```

> **Importante:** O tipo de recurso do projeto Foundry √©
> `Microsoft.CognitiveServices/accounts/projects` (N√ÉO `MachineLearningServices`).

### 4. Criar e iniciar o agente

```powershell
# Criar vers√£o (sem iniciar)
az cognitiveservices agent create `
    --account-name <FOUNDRY> --project-name <PROJECT> `
    --name lg-market-agent `
    --image <ACR>.azurecr.io/lg-market-agent:v1 `
    --cpu 1 --memory 2Gi `
    --protocol responses --protocol-version v1 `
    --env AZURE_AI_PROJECT_ENDPOINT=<PROJECT_ENDPOINT> `
         AZURE_AI_MODEL_DEPLOYMENT_NAME=<MODEL> `
         AZURE_OPENAI_ENDPOINT=https://<FOUNDRY>.openai.azure.com/ `
    --no-start

# Iniciar o agente
az cognitiveservices agent start `
    --account-name <FOUNDRY> --project-name <PROJECT> `
    --name lg-market-agent --agent-version 1
```

O ciclo de vida do agente √©: `Stopped -> Starting -> Started (Running)`.
Aguarde ~2 minutos para o status mudar para Running.

### 5. Testar o agente

```powershell
python test_agent.py
```

## Implanta√ß√£o Automatizada

```powershell
cd lesson-2/langgraph-agent
.\deploy.ps1
```

## Invoca√ß√£o do Agente (Detalhes T√©cnicos)

Agentes hospedados s√£o invocados via **Responses API** com um campo `agent`
no body que identifica o agente e a vers√£o.

### Usando o SDK `azure-ai-projects`

```python
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient

endpoint = "https://<foundry>.services.ai.azure.com/api/projects/<project>"

with (
    DefaultAzureCredential() as credential,
    AIProjectClient(endpoint=endpoint, credential=credential) as client,
    client.get_openai_client() as oai,
):
    response = oai.responses.create(
        input=[{"role": "user", "content": "What's the price of PETR4?"}],
        extra_body={
            "agent": {
                "id": "lg-market-agent",
                "name": "lg-market-agent",
                "version": "3",
                "type": "agent_reference",
            }
        },
    )
    print(response.output_text)
```

### Usando REST diretamente

```python
import requests
from azure.identity import DefaultAzureCredential

credential = DefaultAzureCredential()
token = credential.get_token("https://ai.azure.com/.default").token

url = "https://<foundry>.services.ai.azure.com/api/projects/<project>/openai/responses?api-version=2025-11-15-preview"
body = {
    "input": [{"role": "user", "content": "What's the price of PETR4?"}],
    "agent": {
        "id": "lg-market-agent",
        "name": "lg-market-agent",
        "version": "3",
        "type": "agent_reference",
    },
}
headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}

r = requests.post(url, headers=headers, json=body, timeout=120)
# Extract response text
for item in r.json().get("output", []):
    if item.get("type") == "message":
        for c in item.get("content", []):
            if c.get("type") == "output_text":
                print(c["text"])
```

## Workarounds e Bugs Conhecidos

### 1. AgentReference sem campo `id` (SDK)

O `AgentReference` do SDK `azure-ai-projects==2.0.0b3` n√£o inclui o campo `id`,
mas o servi√ßo Foundry exige este campo. Workaround: construa manualmente o dict
com `id`, `name`, `version` e `type` (veja exemplos acima).

### 2. AgentReference no cont√™iner (agentserver-core)

O servi√ßo Foundry envia um campo `id` ao rotear requisi√ß√µes para o cont√™iner, mas
`azure-ai-agentserver-core==1.0.0b10` rejeita campos desconhecidos em
`AgentReference`. O `main.py` inclui um monkey-patch em
`_patch_agent_reference()` para tratar isso.

### 3. `init_chat_model` requer `azure_endpoint` e `api_version`

Ao usar `init_chat_model("azure_openai:...")` com LangChain, os
par√¢metros `azure_endpoint` e `api_version` s√£o obrigat√≥rios. O cont√™iner recebe o
endpoint via vari√°vel de ambiente `AZURE_OPENAI_ENDPOINT`.

### 4. `az acr build` UnicodeEncodeError no Windows

`az acr build` falha com `UnicodeEncodeError: 'charmap' codec` no
PowerShell 5.1 devido ao colorama. Use `--no-logs` como workaround:

```powershell
az acr build --registry <ACR> --image <TAG> --file Dockerfile . --no-logs
```

### 5. Token audience para invoca√ß√£o

- Endpoint `*.services.ai.azure.com` (projeto): audience `https://ai.azure.com/.default`
- Endpoint `*.openai.azure.com` (OpenAI): audience `https://cognitiveservices.azure.com/.default`

O `client.get_openai_client()` do SDK `AIProjectClient` j√° configura isso
automaticamente (api-version `2025-11-15-preview`).

## Diferen√ßa da Li√ß√£o 1

| Aspecto | Li√ß√£o 1 | Li√ß√£o 2 |
|---|---|---|
| Tipo | Agente baseado em prompt | Agente hospedado (cont√™iner) |
| Framework | SDK direto (`azure-ai-agents`) | LangGraph + adaptador |
| Execu√ß√£o | Serverless no Foundry | Cont√™iner pr√≥prio no Foundry |
| Ferramentas | Code Interpreter (built-in) | Ferramentas customizadas (Python) |
| Complexidade | Simples | M√©dia |

## Vers√µes do SDK Utilizadas

| Pacote | Vers√£o |
|---|---|
| `azure-ai-agentserver-langgraph` | 1.0.0b10 |
| `azure-ai-agentserver-core` | 1.0.0b10 (depend√™ncia) |
| `azure-ai-projects` | 2.0.0b3 (cliente local) |
| `azure-ai-agents` | 1.2.0b5 (depend√™ncia) |
| `langchain` / `langgraph` | Instalado pelo agentserver |
